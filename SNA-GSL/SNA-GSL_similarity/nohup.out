+-----------------------------+------------------------------------------------+
|          Parameter          |                     Value                      |
+=============================+================================================+
| Gt res                      | True                                           |
+-----------------------------+------------------------------------------------+
| Batch size                  | 128                                            |
+-----------------------------+------------------------------------------------+
| Channel align               | True                                           |
+-----------------------------+------------------------------------------------+
| Channel ffn size            | 128                                            |
+-----------------------------+------------------------------------------------+
| Conv channels 0             | 32                                             |
+-----------------------------+------------------------------------------------+
| Conv channels 1             | 64                                             |
+-----------------------------+------------------------------------------------+
| Conv channels 2             | 1                                              |
+-----------------------------+------------------------------------------------+
| Conv channels 3             | 256                                            |
+-----------------------------+------------------------------------------------+
| Conv dropout                | 0.1                                            |
+-----------------------------+------------------------------------------------+
| Conv l relu slope           | 0.33                                           |
+-----------------------------+------------------------------------------------+
| Data dir                    | ../datasets/                                   |
+-----------------------------+------------------------------------------------+
| Dataset                     | LINUX                                          |
+-----------------------------+------------------------------------------------+
| Device                      | cuda:0                                         |
+-----------------------------+------------------------------------------------+
| Dist mat path               | ../datasets/LINUX/LINUX_distance.npy           |
+-----------------------------+------------------------------------------------+
| Dist start decay            | 0.5                                            |
+-----------------------------+------------------------------------------------+
| Dropout                     | 0.1                                            |
+-----------------------------+------------------------------------------------+
| Embedding size              | 32                                             |
+-----------------------------+------------------------------------------------+
| Encoder ffn size            | 128                                            |
+-----------------------------+------------------------------------------------+
| Explain study               | False                                          |
+-----------------------------+------------------------------------------------+
| Gpu index                   | 0                                              |
+-----------------------------+------------------------------------------------+
| Graph transformer active    | True                                           |
+-----------------------------+------------------------------------------------+
| Iter val every              | 1                                              |
+-----------------------------+------------------------------------------------+
| Iter val start              | 9000                                           |
+-----------------------------+------------------------------------------------+
| Iterations                  | 10000                                          |
+-----------------------------+------------------------------------------------+
| Load model                  | False                                          |
+-----------------------------+------------------------------------------------+
| Loaded model signature      | AIDS700nef_2022-05-22_00-09-20-285984          |
+-----------------------------+------------------------------------------------+
| Log file path               | ../GSTLogs/LINUX_2022-05-28_03-03-32-270675/lo |
|                             | g.txt                                          |
+-----------------------------+------------------------------------------------+
| Log path                    | ../GSTLogs                                     |
+-----------------------------+------------------------------------------------+
| Lr                          | 0.0005                                         |
+-----------------------------+------------------------------------------------+
| Lr reduce factor            | 0.5                                            |
+-----------------------------+------------------------------------------------+
| Lr schedule patience        | 800                                            |
+-----------------------------+------------------------------------------------+
| Min lr                      | 1e-06                                          |
+-----------------------------+------------------------------------------------+
| Model save path             | ../GSTLogs/LINUX_2022-05-28_03-03-32-270675/be |
|                             | st_model.pt                                    |
+-----------------------------+------------------------------------------------+
| Msa bias                    | True                                           |
+-----------------------------+------------------------------------------------+
| N channel transformer heads | 4                                              |
+-----------------------------+------------------------------------------------+
| N heads                     | 8                                              |
+-----------------------------+------------------------------------------------+
| Patience                    | 100                                            |
+-----------------------------+------------------------------------------------+
| Pooling res                 | 20                                             |
+-----------------------------+------------------------------------------------+
| Repeat run                  | 0                                              |
+-----------------------------+------------------------------------------------+
| Seed                        | 2022                                           |
+-----------------------------+------------------------------------------------+
| Share qk                    | True                                           |
+-----------------------------+------------------------------------------------+
| Sim mat learning ablation   | False                                          |
+-----------------------------+------------------------------------------------+
| Temp                        | {'cur_iter': 0}                                |
+-----------------------------+------------------------------------------------+
| Use dist                    | True                                           |
+-----------------------------+------------------------------------------------+
| Wandb activate              | False                                          |
+-----------------------------+------------------------------------------------+
| Weight decay                | 0                                              |
+-----------------------------+------------------------------------------------+

Preparing dataset.

model params:330090
+-----------------------------+------------------------------------------------+
|          Parameter          |                     Value                      |
+=============================+================================================+
| Gt res                      | True                                           |
+-----------------------------+------------------------------------------------+
| Batch size                  | 128                                            |
+-----------------------------+------------------------------------------------+
| Channel align               | True                                           |
+-----------------------------+------------------------------------------------+
| Channel ffn size            | 128                                            |
+-----------------------------+------------------------------------------------+
| Conv channels 0             | 32                                             |
+-----------------------------+------------------------------------------------+
| Conv channels 1             | 64                                             |
+-----------------------------+------------------------------------------------+
| Conv channels 2             | 1                                              |
+-----------------------------+------------------------------------------------+
| Conv channels 3             | 256                                            |
+-----------------------------+------------------------------------------------+
| Conv dropout                | 0.1                                            |
+-----------------------------+------------------------------------------------+
| Conv l relu slope           | 0.33                                           |
+-----------------------------+------------------------------------------------+
| Data dir                    | ../datasets/                                   |
+-----------------------------+------------------------------------------------+
| Dataset                     | AIDS700nef                                     |
+-----------------------------+------------------------------------------------+
| Device                      | cuda:1                                         |
+-----------------------------+------------------------------------------------+
| Dist mat path               | ../datasets/AIDS700nef/AIDS700nef_distance.npy |
+-----------------------------+------------------------------------------------+
| Dist start decay            | 0.5                                            |
+-----------------------------+------------------------------------------------+
| Dropout                     | 0.1                                            |
+-----------------------------+------------------------------------------------+
| Embedding size              | 128                                            |
+-----------------------------+------------------------------------------------+
| Encoder ffn size            | 128                                            |
+-----------------------------+------------------------------------------------+
| Explain study               | False                                          |
+-----------------------------+------------------------------------------------+
| Gpu index                   | 1                                              |
+-----------------------------+------------------------------------------------+
| Graph transformer active    | True                                           |
+-----------------------------+------------------------------------------------+
| Iter val every              | 1                                              |
+-----------------------------+------------------------------------------------+
| Iter val start              | 9000                                           |
+-----------------------------+------------------------------------------------+
| Iterations                  | 10000                                          |
+-----------------------------+------------------------------------------------+
| Load model                  | False                                          |
+-----------------------------+------------------------------------------------+
| Loaded model signature      | AIDS700nef_2022-05-22_00-09-20-285984          |
+-----------------------------+------------------------------------------------+
| Log file path               | ../GSTLogs/AIDS700nef_2022-05-28_03-04-11-1316 |
|                             | 71/log.txt                                     |
+-----------------------------+------------------------------------------------+
| Log path                    | ../GSTLogs                                     |
+-----------------------------+------------------------------------------------+
| Lr                          | 0.0005                                         |
+-----------------------------+------------------------------------------------+
| Lr reduce factor            | 0.5                                            |
+-----------------------------+------------------------------------------------+
| Lr schedule patience        | 800                                            |
+-----------------------------+------------------------------------------------+
| Min lr                      | 1e-06                                          |
+-----------------------------+------------------------------------------------+
| Model save path             | ../GSTLogs/AIDS700nef_2022-05-28_03-04-11-1316 |
|                             | 71/best_model.pt                               |
+-----------------------------+------------------------------------------------+
| Msa bias                    | True                                           |
+-----------------------------+------------------------------------------------+
| N channel transformer heads | 4                                              |
+-----------------------------+------------------------------------------------+
| N heads                     | 8                                              |
+-----------------------------+------------------------------------------------+
| Patience                    | 100                                            |
+-----------------------------+------------------------------------------------+
| Pooling res                 | 20                                             |
+-----------------------------+------------------------------------------------+
| Repeat run                  | 0                                              |
+-----------------------------+------------------------------------------------+
| Seed                        | 2022                                           |
+-----------------------------+------------------------------------------------+
| Share qk                    | True                                           |
+-----------------------------+------------------------------------------------+
| Sim mat learning ablation   | False                                          |
+-----------------------------+------------------------------------------------+
| Temp                        | {'cur_iter': 0}                                |
+-----------------------------+------------------------------------------------+
| Use dist                    | True                                           |
+-----------------------------+------------------------------------------------+
| Wandb activate              | False                                          |
+-----------------------------+------------------------------------------------+
| Weight decay                | 0                                              |
+-----------------------------+------------------------------------------------+

Preparing dataset.

model params:884426
+-----------------------------+------------------------------------------------+
|          Parameter          |                     Value                      |
+=============================+================================================+
| Gt res                      | True                                           |
+-----------------------------+------------------------------------------------+
| Batch size                  | 128                                            |
+-----------------------------+------------------------------------------------+
| Channel align               | True                                           |
+-----------------------------+------------------------------------------------+
| Channel ffn size            | 128                                            |
+-----------------------------+------------------------------------------------+
| Conv channels 0             | 32                                             |
+-----------------------------+------------------------------------------------+
| Conv channels 1             | 64                                             |
+-----------------------------+------------------------------------------------+
| Conv channels 2             | 1                                              |
+-----------------------------+------------------------------------------------+
| Conv channels 3             | 256                                            |
+-----------------------------+------------------------------------------------+
| Conv dropout                | 0.1                                            |
+-----------------------------+------------------------------------------------+
| Conv l relu slope           | 0.33                                           |
+-----------------------------+------------------------------------------------+
| Data dir                    | ../datasets/                                   |
+-----------------------------+------------------------------------------------+
| Dataset                     | IMDBMulti                                      |
+-----------------------------+------------------------------------------------+
| Device                      | cuda:2                                         |
+-----------------------------+------------------------------------------------+
| Dist mat path               | ../datasets/IMDBMulti/IMDBMulti_distance.npy   |
+-----------------------------+------------------------------------------------+
| Dist start decay            | 0.5                                            |
+-----------------------------+------------------------------------------------+
| Dropout                     | 0.1                                            |
+-----------------------------+------------------------------------------------+
| Embedding size              | 32                                             |
+-----------------------------+------------------------------------------------+
| Encoder ffn size            | 128                                            |
+-----------------------------+------------------------------------------------+
| Explain study               | False                                          |
+-----------------------------+------------------------------------------------+
| Gpu index                   | 2                                              |
+-----------------------------+------------------------------------------------+
| Graph transformer active    | True                                           |
+-----------------------------+------------------------------------------------+
| Iter val every              | 1                                              |
+-----------------------------+------------------------------------------------+
| Iter val start              | 9000                                           |
+-----------------------------+------------------------------------------------+
| Iterations                  | 10000                                          |
+-----------------------------+------------------------------------------------+
| Load model                  | False                                          |
+-----------------------------+------------------------------------------------+
| Loaded model signature      | AIDS700nef_2022-05-22_00-09-20-285984          |
+-----------------------------+------------------------------------------------+
| Log file path               | ../GSTLogs/IMDBMulti_2022-05-28_03-04-30-63461 |
|                             | 9/log.txt                                      |
+-----------------------------+------------------------------------------------+
| Log path                    | ../GSTLogs                                     |
+-----------------------------+------------------------------------------------+
| Lr                          | 0.0005                                         |
+-----------------------------+------------------------------------------------+
| Lr reduce factor            | 0.5                                            |
+-----------------------------+------------------------------------------------+
| Lr schedule patience        | 800                                            |
+-----------------------------+------------------------------------------------+
| Min lr                      | 1e-06                                          |
+-----------------------------+------------------------------------------------+
| Model save path             | ../GSTLogs/IMDBMulti_2022-05-28_03-04-30-63461 |
|                             | 9/best_model.pt                                |
+-----------------------------+------------------------------------------------+
| Msa bias                    | True                                           |
+-----------------------------+------------------------------------------------+
| N channel transformer heads | 8                                              |
+-----------------------------+------------------------------------------------+
| N heads                     | 8                                              |
+-----------------------------+------------------------------------------------+
| Patience                    | 100                                            |
+-----------------------------+------------------------------------------------+
| Pooling res                 | 20                                             |
+-----------------------------+------------------------------------------------+
| Repeat run                  | 0                                              |
+-----------------------------+------------------------------------------------+
| Seed                        | 2022                                           |
+-----------------------------+------------------------------------------------+
| Share qk                    | True                                           |
+-----------------------------+------------------------------------------------+
| Sim mat learning ablation   | False                                          |
+-----------------------------+------------------------------------------------+
| Temp                        | {'cur_iter': 0}                                |
+-----------------------------+------------------------------------------------+
| Use dist                    | True                                           |
+-----------------------------+------------------------------------------------+
| Wandb activate              | False                                          |
+-----------------------------+------------------------------------------------+
| Weight decay                | 0                                              |
+-----------------------------+------------------------------------------------+

Preparing dataset.

model params:5434082
+-----------------------------+------------------------------------------------+
|          Parameter          |                     Value                      |
+=============================+================================================+
| Gt res                      | True                                           |
+-----------------------------+------------------------------------------------+
| Batch size                  | 128                                            |
+-----------------------------+------------------------------------------------+
| Channel align               | True                                           |
+-----------------------------+------------------------------------------------+
| Channel ffn size            | 128                                            |
+-----------------------------+------------------------------------------------+
| Conv channels 0             | 32                                             |
+-----------------------------+------------------------------------------------+
| Conv channels 1             | 64                                             |
+-----------------------------+------------------------------------------------+
| Conv channels 2             | 1                                              |
+-----------------------------+------------------------------------------------+
| Conv channels 3             | 256                                            |
+-----------------------------+------------------------------------------------+
| Conv dropout                | 0.1                                            |
+-----------------------------+------------------------------------------------+
| Conv l relu slope           | 0.33                                           |
+-----------------------------+------------------------------------------------+
| Data dir                    | ../datasets/                                   |
+-----------------------------+------------------------------------------------+
| Dataset                     | LINUX                                          |
+-----------------------------+------------------------------------------------+
| Device                      | cuda:3                                         |
+-----------------------------+------------------------------------------------+
| Dist mat path               | ../datasets/LINUX/LINUX_distance.npy           |
+-----------------------------+------------------------------------------------+
| Dist start decay            | 0.5                                            |
+-----------------------------+------------------------------------------------+
| Dropout                     | 0.1                                            |
+-----------------------------+------------------------------------------------+
| Embedding size              | 32                                             |
+-----------------------------+------------------------------------------------+
| Encoder ffn size            | 128                                            |
+-----------------------------+------------------------------------------------+
| Explain study               | False                                          |
+-----------------------------+------------------------------------------------+
| Gpu index                   | 3                                              |
+-----------------------------+------------------------------------------------+
| Graph transformer active    | True                                           |
+-----------------------------+------------------------------------------------+
| Iter val every              | 1                                              |
+-----------------------------+------------------------------------------------+
| Iter val start              | 9000                                           |
+-----------------------------+------------------------------------------------+
| Iterations                  | 10000                                          |
+-----------------------------+------------------------------------------------+
| Load model                  | False                                          |
+-----------------------------+------------------------------------------------+
| Loaded model signature      | AIDS700nef_2022-05-22_00-09-20-285984          |
+-----------------------------+------------------------------------------------+
| Log file path               | ../GSTLogs/LINUX_2022-05-28_03-05-14-382725/lo |
|                             | g.txt                                          |
+-----------------------------+------------------------------------------------+
| Log path                    | ../GSTLogs                                     |
+-----------------------------+------------------------------------------------+
| Lr                          | 0.0005                                         |
+-----------------------------+------------------------------------------------+
| Lr reduce factor            | 0.5                                            |
+-----------------------------+------------------------------------------------+
| Lr schedule patience        | 800                                            |
+-----------------------------+------------------------------------------------+
| Min lr                      | 1e-06                                          |
+-----------------------------+------------------------------------------------+
| Model save path             | ../GSTLogs/LINUX_2022-05-28_03-05-14-382725/be |
|                             | st_model.pt                                    |
+-----------------------------+------------------------------------------------+
| Msa bias                    | True                                           |
+-----------------------------+------------------------------------------------+
| N channel transformer heads | 4                                              |
+-----------------------------+------------------------------------------------+
| N heads                     | 8                                              |
+-----------------------------+------------------------------------------------+
| Patience                    | 100                                            |
+-----------------------------+------------------------------------------------+
| Pooling res                 | 20                                             |
+-----------------------------+------------------------------------------------+
| Repeat run                  | 0                                              |
+-----------------------------+------------------------------------------------+
| Seed                        | 2022                                           |
+-----------------------------+------------------------------------------------+
| Share qk                    | True                                           |
+-----------------------------+------------------------------------------------+
| Sim mat learning ablation   | False                                          |
+-----------------------------+------------------------------------------------+
| Temp                        | {'cur_iter': 0}                                |
+-----------------------------+------------------------------------------------+
| Use dist                    | True                                           |
+-----------------------------+------------------------------------------------+
| Wandb activate              | False                                          |
+-----------------------------+------------------------------------------------+
| Weight decay                | 0                                              |
+-----------------------------+------------------------------------------------+

Preparing dataset.

model params:330090
GTCNet(
  (embedding_learning): GCNTransformerEncoder(
    (GCN_first): DenseGCNConv(36, 128)
    (GCN_second): DenseGCNConv(128, 128)
    (GCN_third): DenseGCNConv(128, 128)
    (self_attention_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (self_attention): MultiHeadAttention(
      (linear_q): Linear(in_features=128, out_features=1024, bias=True)
      (linear_k): Linear(in_features=128, out_features=1024, bias=True)
      (linear_v): Linear(in_features=128, out_features=1024, bias=True)
      (att_dropout): Dropout(p=0.1, inplace=False)
      (output_layer): Linear(in_features=1024, out_features=128, bias=True)
    )
    (self_attention_dropout): Dropout(p=0.1, inplace=False)
    (ffn_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (ffn): FeedForwardNetwork(
      (layer1): Linear(in_features=128, out_features=128, bias=True)
      (gelu): GELU()
      (layer2): Linear(in_features=128, out_features=128, bias=True)
    )
    (ffn_dropout): Dropout(p=0.1, inplace=False)
  )
  (embedding_interaction): CrossTransformer(
    (cross_attention): CrossAttention(
      (linear_q): Linear(in_features=128, out_features=1024, bias=True)
      (linear_k): Linear(in_features=128, out_features=1024, bias=True)
    )
  )
  (sim_mat_learning): SimMatLearning(
    (channel_alignment): ChannelAlignment(
      (self_attention_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
      (self_attention): MultiHeadAttention(
        (linear_q): Linear(in_features=100, out_features=400, bias=True)
        (linear_k): Linear(in_features=100, out_features=400, bias=True)
        (linear_v): Linear(in_features=100, out_features=400, bias=True)
        (att_dropout): Dropout(p=0.1, inplace=False)
        (output_layer): Linear(in_features=400, out_features=100, bias=True)
      )
      (self_attention_dropout): Dropout(p=0.1, inplace=False)
      (ffn_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
      (ffn): FeedForwardNetwork(
        (layer1): Linear(in_features=100, out_features=128, bias=True)
        (gelu): GELU()
        (layer2): Linear(in_features=128, out_features=100, bias=True)
      )
      (ffn_dropout): Dropout(p=0.1, inplace=False)
    )
    (sim_CNN): SimCNN(
      (e2econv1): E2EBlock(
        (cnn1): Conv2d(16, 32, kernel_size=(1, 10), stride=(1, 1))
        (cnn2): Conv2d(16, 32, kernel_size=(10, 1), stride=(1, 1))
      )
      (e2econv2): E2EBlock(
        (cnn1): Conv2d(32, 64, kernel_size=(1, 10), stride=(1, 1))
        (cnn2): Conv2d(32, 64, kernel_size=(10, 1), stride=(1, 1))
      )
      (E2N): Conv2d(64, 1, kernel_size=(1, 10), stride=(1, 1))
      (N2G): Conv2d(1, 256, kernel_size=(10, 1), stride=(1, 1))
      (fc_1): Linear(in_features=256, out_features=128, bias=True)
      (fc_2): Linear(in_features=128, out_features=64, bias=True)
      (fc_3): Linear(in_features=64, out_features=32, bias=True)
      (fc_4): Linear(in_features=32, out_features=1, bias=True)
    )
  )
)

Model training.

Iteration = 0
	batch loss = 35.75649422903856 (e-3)
	rho = -0.1832465484364387 
	tau = -0.1209484026589898 @ 0:00:01.106793
Iteration = 500
	batch loss = 2.560518371562163 (e-3)
	rho = 0.8900985645686742 
	tau = 0.7243378798997102 @ 0:04:39.159038
Epoch  2533: reducing learning rate of group 0 to 2.5000e-04.
Iteration = 1000
	batch loss = 2.316207935412725 (e-3)
	rho = 0.8845408119488093 
	tau = 0.7368598282631633 @ 0:05:41.316833
Epoch  4482: reducing learning rate of group 0 to 1.2500e-04.
Iteration = 1500
	batch loss = 1.4001068969567616 (e-3)
	rho = 0.9387491690064427 
	tau = 0.7984696665648132 @ 0:05:35.331460
Iteration = 2000
	batch loss = 1.4173419525225956 (e-3)
	rho = 0.9217699850768338 
	tau = 0.7805482263946079 @ 0:05:40.542526
Epoch  6317: reducing learning rate of group 0 to 6.2500e-05.
Epoch  7247: reducing learning rate of group 0 to 3.1250e-05.
Iteration = 2500
	batch loss = 1.371649947638313 (e-3)
	rho = 0.9522057782266452 
	tau = 0.8285940889154314 @ 0:05:36.026117
Epoch  8048: reducing learning rate of group 0 to 1.5625e-05.
Iteration = 3000
	batch loss = 1.2397745934625466 (e-3)
	rho = 0.9465131530814208 
	tau = 0.8222604083391822 @ 0:05:34.991539
Epoch  9613: reducing learning rate of group 0 to 7.8125e-06.
Iteration = 3500
	batch loss = 1.269525266252458 (e-3)
	rho = 0.9511691413576352 
	tau = 0.8385996633751263 @ 0:05:46.621503
Epoch 11503: reducing learning rate of group 0 to 3.9063e-06.
Iteration = 4000
	batch loss = 1.4150458543250959 (e-3)
	rho = 0.9446364621556776 
	tau = 0.8151993352956913 @ 0:05:34.247539
Epoch 12304: reducing learning rate of group 0 to 1.9531e-06.
Epoch 13128: reducing learning rate of group 0 to 1.0000e-06.
Iteration = 4500
	batch loss = 1.0077556556401153 (e-3)
	rho = 0.9657386127712471 
	tau = 0.8556094339940282 @ 0:05:41.846027
Iteration = 5000
	batch loss = 1.1738270210723083 (e-3)
	rho = 0.9341189237748335 
	tau = 0.8046660688804846 @ 0:05:33.147834
Iteration = 5500
	batch loss = 1.1108543646211426 (e-3)
	rho = 0.9573083757722335 
	tau = 0.8359398645415856 @ 0:05:32.125875
Iteration = 6000
	batch loss = 1.0992076713591814 (e-3)
	rho = 0.943664939481738 
	tau = 0.8113099796296406 @ 0:05:35.659995
Iteration = 6500
	batch loss = 1.0755521555741627 (e-3)
	rho = 0.9584439347648379 
	tau = 0.8361858487532796 @ 0:05:24.484395
Iteration = 7000
	batch loss = 1.2822132169579465 (e-3)
	rho = 0.9553885618543622 
	tau = 0.8372635023381094 @ 0:05:29.840820
Iteration = 7500
	batch loss = 1.1280167770261567 (e-3)
	rho = 0.9548915044752054 
	tau = 0.8371318906038051 @ 0:05:32.792332
Iteration = 8000
	batch loss = 1.1251822191600998 (e-3)
	rho = 0.9641597019692196 
	tau = 0.8491365882219484 @ 0:05:38.885724
Iteration = 8500
	batch loss = 1.2337700075780351 (e-3)
	rho = 0.9485915088251772 
	tau = 0.8277579707106948 @ 0:05:31.674100
	validation mse decreased ( 10000000000000.0 ---> 2.3782077444983383 (e-3) ), and save the model ... 
Iteration = 9000
	batch loss = 1.268966627928118 (e-3)
	rho = 0.9548302597969737 
	tau = 0.8315097018956208 @ 0:05:46.360681
	validation mse decreased ( 2.3782077444983383 ---> 1.8796967608588082 (e-3) ), and save the model ... 
	validation mse: 2.4831098371318405
	validation mse: 2.0868251632366865
	validation mse: 2.085312309541872
	validation mse: 2.3418074207646504
	validation mse: 2.1050688943692615
	validation mse: 2.702876719247018
	validation mse: 2.1318474518401285
	validation mse decreased ( 1.8796967608588082 ---> 1.851646149797099 (e-3) ), and save the model ... 
	validation mse decreased ( 1.851646149797099 ---> 1.7584235274365971 (e-3) ), and save the model ... 
	validation mse: 1.9160949758120944
	validation mse: 1.8990597022431237
	validation mse: 2.259869208293302
	validation mse: 2.1921481671077863
	validation mse: 1.8659909122756548
	validation mse: 2.376464368509395
	validation mse: 1.8150864568139826
	validation mse: 2.3156411679727693
	validation mse: 1.7905979716618148
	validation mse: 2.217006350734404
	validation mse: 2.5721821933984756
	validation mse: 2.669018507003784
	validation mse: 1.789631455072335
	validation mse: 2.1466205029615333
	validation mse decreased ( 1.7584235274365971 ---> 1.5445650688239505 (e-3) ), and save the model ... 
	validation mse: 2.5575294824583192
	validation mse: 1.8392643758228846
	validation mse: 1.9060321950486727
	validation mse: 1.6370481412325588
	validation mse: 2.4614422981228143
	validation mse: 2.0504773993577277
	validation mse: 2.13709594681859
	validation mse: 2.3552484810352325
	validation mse: 2.4160467088222504
	validation mse: 1.9575058848464062
	validation mse: 2.1965033507772853
	validation mse: 1.9602910349411622
	validation mse: 2.199666734252657
	validation mse: 2.1931373115096773
	validation mse: 2.701650240591594
	validation mse: 1.8825683343623365
	validation mse: 2.0827149174043114
	validation mse: 2.6351297540324077
	validation mse decreased ( 1.5445650688239505 ---> 1.5038598594920978 (e-3) ), and save the model ... 
	validation mse: 1.7214491364679168
	validation mse: 2.5499500201216767
	validation mse: 2.4302984454802106
	validation mse: 1.6207722680909293
	validation mse: 1.832055752830846
	validation mse: 2.2496839985251427
	validation mse: 2.4263280044708933
	validation mse: 1.6520201228559017
	validation mse: 2.0279273656862125
	validation mse: 1.93490596222026
	validation mse: 2.5810563138553078
	validation mse: 2.605472305523498
	validation mse: 1.8925640199865614
	validation mse: 2.1411247252087504
	validation mse: 2.4145233977053846
	validation mse: 2.7306956172521626
	validation mse: 2.0570134477955957
	validation mse: 2.351509912737778
	validation mse: 2.1941389489386762
	validation mse: 2.7663474902510643
	validation mse: 1.92341006227902
	validation mse: 2.2313077667994157
	validation mse: 1.9844674771385533
	validation mse: 1.9996789483619588
	validation mse: 2.2625181557876726
	validation mse: 2.2638764897627492
	validation mse: 2.035936580172607
	validation mse: 2.123698232961553
	validation mse: 2.561253149594579
	validation mse: 2.827760124845164
	validation mse: 2.096843706177814
	validation mse: 1.9973638866628918
	validation mse: 2.2104683199099133
	validation mse: 2.625383050846202
	validation mse: 2.140501673732485
	validation mse: 2.003352876220431
	validation mse: 2.2219888400286436
	validation mse: 2.1530579775571823
	validation mse: 2.183541389448302
	validation mse: 2.1745809486934116
	validation mse: 1.802593469619751
	validation mse: 2.3040395762239183
	validation mse: 1.9628072556640421
	validation mse: 1.957299068037953
	validation mse: 2.6182842840041434
	validation mse: 2.4152092103447234
	validation mse: 1.852186702724014
	validation mse: 2.241012267768383
	validation mse: 2.227504351841552
	validation mse: 2.052599298102515
	validation mse: 2.507526267852102
	validation mse: 2.2194510591881618
	validation mse: 2.206341942240085
	validation mse: 3.4889477704252516
	validation mse: 2.3994829106543745
	validation mse: 2.4299974154148782
	validation mse: 2.196857758930751
	validation mse: 2.1622429801417247
	validation mse: 1.9770558990005938
	validation mse: 2.5643106483455216
	validation mse: 1.7222427763044834
	validation mse: 2.331826649606228
	validation mse: 1.8962833232113294
	validation mse: 1.5594878500061375
	validation mse: 1.7879645606236798
	validation mse: 1.8232974356838636
	validation mse: 1.6001583077013493
	validation mse: 2.3131080171359435
	validation mse: 2.470700243221862
	validation mse: 2.051011073802199
	validation mse: 1.8558759109250136
	validation mse: 2.1112616306969096
	validation mse: 2.4272521691662923
	validation mse: 2.3678280413150787
	validation mse: 1.9450759515166283
	validation mse: 1.6569310666194985
	validation mse: 2.183802958045687
	validation mse: 1.5492273760693416
	validation mse: 2.4638516196448887
	validation mse: 2.8415136837533543
	validation mse: 3.14679422548839
	validation mse: 2.2899903223982876
	validation mse: 1.9375676954431194
	validation mse: 2.079299384994166
	validation mse: 2.108859324029514
	validation mse: 2.768552941935403
	validation mse: 1.9840162180896317
	validation mse: 3.2039999296622614
	validation mse: 3.506176173686981
	validation mse: 1.8980851396918297
	validation mse: 3.051408433488437
	validation mse: 1.6477950981685094
	validation mse: 2.3132259026169777
	validation mse: 1.8874982105834142
	validation mse: 2.033828425088099
	validation mse: 2.8703718978379453
	validation mse: 1.9979771093598433
	validation mse: 1.8847518068339144
	validation mse: 1.8409816814320428
	validation mse: 2.1551931543009624

Model evaluation.
Test results:
	 test_mse = 1.7215173330828712
	 test_rho = 0.9012682560508556
	 test_tau = 0.7599284478705656
	 test_p10 = 0.5864285714285714
	 test_p20 = 0.6603571428571429
Model params:884426
GTCNet(
  (embedding_learning): GCNTransformerEncoder(
    (GCN_first): DenseGCNConv(8, 32)
    (GCN_second): DenseGCNConv(32, 32)
    (GCN_third): DenseGCNConv(32, 32)
    (self_attention_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (self_attention): MultiHeadAttention(
      (linear_q): Linear(in_features=32, out_features=256, bias=True)
      (linear_k): Linear(in_features=32, out_features=256, bias=True)
      (linear_v): Linear(in_features=32, out_features=256, bias=True)
      (att_dropout): Dropout(p=0.1, inplace=False)
      (output_layer): Linear(in_features=256, out_features=32, bias=True)
    )
    (self_attention_dropout): Dropout(p=0.1, inplace=False)
    (ffn_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ffn): FeedForwardNetwork(
      (layer1): Linear(in_features=32, out_features=128, bias=True)
      (gelu): GELU()
      (layer2): Linear(in_features=128, out_features=32, bias=True)
    )
    (ffn_dropout): Dropout(p=0.1, inplace=False)
  )
  (embedding_interaction): CrossTransformer(
    (cross_attention): CrossAttention(
      (linear_q): Linear(in_features=32, out_features=256, bias=True)
      (linear_k): Linear(in_features=32, out_features=256, bias=True)
    )
  )
  (sim_mat_learning): SimMatLearning(
    (channel_alignment): ChannelAlignment(
      (self_attention_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
      (self_attention): MultiHeadAttention(
        (linear_q): Linear(in_features=100, out_features=400, bias=True)
        (linear_k): Linear(in_features=100, out_features=400, bias=True)
        (linear_v): Linear(in_features=100, out_features=400, bias=True)
        (att_dropout): Dropout(p=0.1, inplace=False)
        (output_layer): Linear(in_features=400, out_features=100, bias=True)
      )
      (self_attention_dropout): Dropout(p=0.1, inplace=False)
      (ffn_norm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)
      (ffn): FeedForwardNetwork(
        (layer1): Linear(in_features=100, out_features=128, bias=True)
        (gelu): GELU()
        (layer2): Linear(in_features=128, out_features=100, bias=True)
      )
      (ffn_dropout): Dropout(p=0.1, inplace=False)
    )
    (sim_CNN): SimCNN(
      (e2econv1): E2EBlock(
        (cnn1): Conv2d(16, 32, kernel_size=(1, 10), stride=(1, 1))
        (cnn2): Conv2d(16, 32, kernel_size=(10, 1), stride=(1, 1))
      )
      (e2econv2): E2EBlock(
        (cnn1): Conv2d(32, 64, kernel_size=(1, 10), stride=(1, 1))
        (cnn2): Conv2d(32, 64, kernel_size=(10, 1), stride=(1, 1))
      )
      (E2N): Conv2d(64, 1, kernel_size=(1, 10), stride=(1, 1))
      (N2G): Conv2d(1, 256, kernel_size=(10, 1), stride=(1, 1))
      (fc_1): Linear(in_features=256, out_features=128, bias=True)
      (fc_2): Linear(in_features=128, out_features=64, bias=True)
      (fc_3): Linear(in_features=64, out_features=32, bias=True)
      (fc_4): Linear(in_features=32, out_features=1, bias=True)
    )
  )
)

Model training.

Iteration = 0
	batch loss = 41.762339882552624 (e-3)
	rho = 0.09726352935064164 
	tau = 0.06893880949370224 @ 0:00:02.110559
Iteration = 500
	batch loss = 0.7634104986209422 (e-3)
	rho = 0.9909696724277249 
	tau = 0.9306685600443461 @ 0:07:29.363951
Epoch  2665: reducing learning rate of group 0 to 2.5000e-04.
Iteration = 1000
	batch loss = 0.49179146299138665 (e-3)
	rho = 0.9907004627255063 
	tau = 0.9348268629146581 @ 0:07:15.714410
Epoch  5992: reducing learning rate of group 0 to 1.2500e-04.
Iteration = 1500
	batch loss = 0.39234088762896135 (e-3)
	rho = 0.991121612965628 
	tau = 0.9340654221177036 @ 0:07:26.916006
Epoch  7417: reducing learning rate of group 0 to 6.2500e-05.
Iteration = 2000
	batch loss = 0.2846345887519419 (e-3)
	rho = 0.9941012303428336 
	tau = 0.9458710792477116 @ 0:07:05.900439
Epoch  8950: reducing learning rate of group 0 to 3.1250e-05.
Epoch  9751: reducing learning rate of group 0 to 1.5625e-05.
Iteration = 2500
	batch loss = 0.2788105011859443 (e-3)
	rho = 0.994280799951506 
	tau = 0.9525931126126368 @ 0:07:13.479975
Epoch 10552: reducing learning rate of group 0 to 7.8125e-06.
Iteration = 3000
	batch loss = 0.23078252706909552 (e-3)
	rho = 0.9951836889077746 
	tau = 0.9543278540005273 @ 0:07:17.170477
Epoch 12460: reducing learning rate of group 0 to 3.9063e-06.
Epoch 13261: reducing learning rate of group 0 to 1.9531e-06.
Iteration = 3500
	batch loss = 0.19376593627384864 (e-3)
	rho = 0.9962063146514926 
	tau = 0.9590180252748589 @ 0:07:13.325734
Epoch 14062: reducing learning rate of group 0 to 1.0000e-06.
Iteration = 4000
	batch loss = 0.24201512133004144 (e-3)
	rho = 0.9955978521144723 
	tau = 0.9599579137352248 @ 0:07:14.646430
Iteration = 4500
	batch loss = 0.26594447263050824 (e-3)
	rho = 0.9944447810301584 
	tau = 0.9496481138333 @ 0:07:23.055938
Iteration = 5000
	batch loss = 0.21893958910368383 (e-3)
	rho = 0.996109131674684 
	tau = 0.9585123015003076 @ 0:07:26.144842
Iteration = 5500
	batch loss = 0.24061399017227814 (e-3)
	rho = 0.995712611413672 
	tau = 0.9563482876462069 @ 0:07:17.950409
Iteration = 6000
	batch loss = 0.18568069208413363 (e-3)
	rho = 0.9921014443875997 
	tau = 0.9431995694642588 @ 0:07:05.503355
Iteration = 6500
	batch loss = 0.24385420692851767 (e-3)
	rho = 0.9943860952574657 
	tau = 0.9496843115151081 @ 0:07:07.465379
Iteration = 7000
	batch loss = 0.28268570167711005 (e-3)
	rho = 0.9918624229697404 
	tau = 0.944854053361167 @ 0:07:17.049173
Iteration = 7500
	batch loss = 0.253073732892517 (e-3)
	rho = 0.9956092952086705 
	tau = 0.9560602095751918 @ 0:04:00.167869
Iteration = 8000
	batch loss = 0.2364057581871748 (e-3)
	rho = 0.9934833888506496 
	tau = 0.9478438246734338 @ 0:03:43.118181
Iteration = 8500
	batch loss = 0.20363335715956055 (e-3)
	rho = 0.9974590398325596 
	tau = 0.9677323364638015 @ 0:03:36.609143
	validation mse decreased ( 10000000000000.0 ---> 0.31613503582775593 (e-3) ), and save the model ... 
Iteration = 9000
	batch loss = 0.20128033065702766 (e-3)
	rho = 0.9955866309186158 
	tau = 0.9529627788509939 @ 0:03:42.785872
	validation mse: 0.3580021392554045
	validation mse: 0.670605730265379
	validation mse: 0.3535090945661068
	validation mse: 0.4695887118577957
	validation mse: 0.3574538044631481
	validation mse decreased ( 0.31613503582775593 ---> 0.19909892231225967 (e-3) ), and save the model ... 
	validation mse: 0.4824777599424124
	validation mse: 0.4151599295437336
	validation mse: 0.7934171427041292
	validation mse: 0.5262250266969204
	validation mse: 0.6843989714980125
	validation mse: 0.3735581040382385
	validation mse: 0.522325225174427
	validation mse: 0.3285510651767254
	validation mse: 0.36803177557885647
	validation mse: 0.6992128863930702
	validation mse: 0.9196923300623894
	validation mse: 0.3229214623570442
	validation mse: 0.3137819282710552
	validation mse: 0.5131187196820974
	validation mse: 0.35814737901091576
	validation mse: 0.45439451932907104
	validation mse: 0.2533917874097824
	validation mse: 0.2721019461750984
	validation mse: 0.46636748127639294
	validation mse: 0.4585503786802292
	validation mse: 0.2937440015375614
	validation mse: 0.4943273961544037
	validation mse: 0.44212572276592255
	validation mse: 0.6021764129400253
	validation mse: 0.5449210107326508
	validation mse: 0.654481677338481
	validation mse: 0.43568577617406845
	validation mse: 0.43723633978515863
	validation mse: 0.6968346610665321
	validation mse: 0.3257214277982712
	validation mse: 0.6096141878515482
	validation mse: 0.43485794216394424
	validation mse: 0.4541880916804075
	validation mse: 0.3858259506523609
	validation mse: 0.3994531184434891
	validation mse: 0.5442400090396404
	validation mse: 0.5994956754148006
	validation mse: 0.4536896478384733
	validation mse: 0.4079948365688324
	validation mse: 0.3360227681696415
	validation mse: 0.5563691072165966
	validation mse: 0.4971803538501262
	validation mse: 0.6026056781411171
	validation mse: 0.3523674048483372
	validation mse: 0.41795398108661175
	validation mse: 0.5406423658132553
	validation mse: 0.8106439933180809
	validation mse: 0.40425652638077736
	validation mse: 0.5944809503853321
	validation mse: 0.427801888436079
	validation mse: 0.735377874225378
	validation mse: 0.3027980960905552
	validation mse: 0.3148450143635273
	validation mse: 0.6486095488071442
	validation mse: 0.44640861451625824
	validation mse: 0.340990275144577
	validation mse: 0.7352745346724987
	validation mse: 0.29256943613290787
	validation mse decreased ( 0.19909892231225967 ---> 0.19759525544941425 (e-3) ), and save the model ... 
	validation mse: 0.7430549524724483
	validation mse: 0.3031607437878847
	validation mse: 0.6523559242486954
	validation mse: 0.7652903534471989
	validation mse: 0.6496651284396648
	validation mse: 0.3484414517879486
	validation mse: 0.4649021103978157
	validation mse: 0.6537177413702011
	validation mse: 0.587762612849474
	validation mse: 0.5350511241704226
	validation mse: 0.41160622611641884
	validation mse: 0.8365127583965659
	validation mse: 0.35691240802407265
	validation mse: 0.33512698486447334
	validation mse: 0.46890953555703163
	validation mse: 0.362040139734745
	validation mse: 0.2706400491297245
	validation mse: 0.3581992210820317
	validation mse: 0.28383195400238037
	validation mse: 0.5635105445981026
	validation mse: 0.7530816271901131
	validation mse: 0.32347350381314754
	validation mse: 0.3687813156284392
	validation mse: 0.3294961806386709
	validation mse: 0.4673665389418602
	validation mse: 0.4489932209253311
	validation mse: 0.7722951099276543
	validation mse: 0.45117685571312904
	validation mse: 0.203015161678195
	validation mse: 0.3288229927420616
	validation mse: 0.5114824138581753
	validation mse: 0.5129074398428202
	validation mse: 0.594475157558918
	validation mse: 0.9175256639719009
	validation mse: 0.545839611440897
	validation mse: 0.44692346826195717
	validation mse: 0.517625231295824
	validation mse: 0.4905522428452968
	validation mse: 0.6741826049983501
	validation mse: 0.3130740765482187
	validation mse: 0.5052939802408218
	validation mse: 0.7673507742583752
	validation mse: 1.080690175294876
	validation mse: 0.5302179232239723
	validation mse: 0.4626780189573765
	validation mse: 0.4904724285006523
	validation mse: 0.26784690096974373
	validation mse: 0.7801106944680214
	validation mse: 0.3160554729402065
	validation mse: 0.4298037476837635
	validation mse: 0.3028294211253524
	validation mse: 0.43722810223698616
	validation mse: 0.6386625859886408
	validation mse: 0.6243915855884552
	validation mse: 0.665962528437376
	validation mse: 0.5104581825435162
	validation mse: 0.8957513235509396
	validation mse: 0.7210146263241768
	validation mse: 0.45158781111240387
	validation mse: 0.65854761749506
	validation mse: 0.2954217419028282
	validation mse: 0.42365502566099167
	validation mse: 0.6812549009919167
	validation mse: 0.4501431994140148
	validation mse: 0.36899447441101074
	validation mse: 0.5864594131708145
	validation mse: 0.32483983784914017
	validation mse: 0.497394548729062
	validation mse: 0.36523181945085526
	validation mse: 0.5496504902839661
	validation mse: 0.5186592508107424
	validation mse: 0.43221827130764723
	validation mse: 0.584119725972414
	validation mse: 0.4319843929260969
	validation mse: 0.9036961570382118
	validation mse: 0.5517697241157293
	validation mse: 0.7603078568354249
	validation mse: 0.38435247726738453
	validation mse: 0.6415287777781487
	validation mse: 0.5952800251543522
	validation mse: 0.2742434851825237
	validation mse: 0.6383243016898632
	validation mse: 0.5556185450404882
	validation mse: 0.5308869853615761
	validation mse: 0.2251780778169632
	validation mse: 0.718416403979063
	validation mse: 0.4257657378911972
	validation mse: 0.3431518655270338
	validation mse: 0.63035455532372
	validation mse: 0.4969917982816696
	validation mse: 0.5142387375235558
	validation mse: 0.5351826921105385
	validation mse: 0.790988989174366
	validation mse: 0.7632884383201599
	validation mse: 0.8265233039855957
	validation mse: 0.33452577888965607
	validation mse: 0.5992349795997143
	validation mse: 0.5241353437304497
	validation mse: 0.3159287851303816
	validation mse: 0.45574513264000416

Model evaluation.
Test results:
	 test_mse = 0.21681464824060784
	 test_rho = 0.991690030894928
	 test_tau = 0.9579651409481823
	 test_p10 = 0.991
	 test_p20 = 0.9682499999999998
Model params:330090
GTCNet(
  (embedding_learning): GCNTransformerEncoder(
    (GCN_first): DenseGCNConv(89, 32)
    (GCN_second): DenseGCNConv(32, 32)
    (GCN_third): DenseGCNConv(32, 32)
    (self_attention_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (self_attention): MultiHeadAttention(
      (linear_q): Linear(in_features=32, out_features=256, bias=True)
      (linear_k): Linear(in_features=32, out_features=256, bias=True)
      (linear_v): Linear(in_features=32, out_features=256, bias=True)
      (att_dropout): Dropout(p=0.1, inplace=False)
      (output_layer): Linear(in_features=256, out_features=32, bias=True)
    )
    (self_attention_dropout): Dropout(p=0.1, inplace=False)
    (ffn_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
    (ffn): FeedForwardNetwork(
      (layer1): Linear(in_features=32, out_features=128, bias=True)
      (gelu): GELU()
      (layer2): Linear(in_features=128, out_features=32, bias=True)
    )
    (ffn_dropout): Dropout(p=0.1, inplace=False)
  )
  (embedding_interaction): CrossTransformer(
    (cross_attention): CrossAttention(
      (linear_q): Linear(in_features=32, out_features=256, bias=True)
      (linear_k): Linear(in_features=32, out_features=256, bias=True)
    )
    (pooling): AdaptiveAvgPool2d(output_size=(20, 20))
  )
  (sim_mat_learning): SimMatLearning(
    (channel_alignment): ChannelAlignment(
      (self_attention_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)
      (self_attention): MultiHeadAttention(
        (linear_q): Linear(in_features=400, out_features=3200, bias=True)
        (linear_k): Linear(in_features=400, out_features=3200, bias=True)
        (linear_v): Linear(in_features=400, out_features=3200, bias=True)
        (att_dropout): Dropout(p=0.1, inplace=False)
        (output_layer): Linear(in_features=3200, out_features=400, bias=True)
      )
      (self_attention_dropout): Dropout(p=0.1, inplace=False)
      (ffn_norm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)
      (ffn): FeedForwardNetwork(
        (layer1): Linear(in_features=400, out_features=128, bias=True)
        (gelu): GELU()
        (layer2): Linear(in_features=128, out_features=400, bias=True)
      )
      (ffn_dropout): Dropout(p=0.1, inplace=False)
    )
    (sim_CNN): SimCNN(
      (e2econv1): E2EBlock(
        (cnn1): Conv2d(16, 32, kernel_size=(1, 20), stride=(1, 1))
        (cnn2): Conv2d(16, 32, kernel_size=(20, 1), stride=(1, 1))
      )
      (e2econv2): E2EBlock(
        (cnn1): Conv2d(32, 64, kernel_size=(1, 20), stride=(1, 1))
        (cnn2): Conv2d(32, 64, kernel_size=(20, 1), stride=(1, 1))
      )
      (E2N): Conv2d(64, 1, kernel_size=(1, 20), stride=(1, 1))
      (N2G): Conv2d(1, 256, kernel_size=(20, 1), stride=(1, 1))
      (fc_1): Linear(in_features=256, out_features=128, bias=True)
      (fc_2): Linear(in_features=128, out_features=64, bias=True)
      (fc_3): Linear(in_features=64, out_features=32, bias=True)
      (fc_4): Linear(in_features=32, out_features=1, bias=True)
    )
  )
)

Model training.

Iteration = 0
	batch loss = 161.62432304450445 (e-3)
	rho = -0.16442171013487072 
	tau = -0.10356930931024687 @ 0:00:03.145652
Epoch  3399: reducing learning rate of group 0 to 2.5000e-04.
Iteration = 500
	batch loss = 1.1600226696048463 (e-3)
	rho = 0.9762501167371234 
	tau = 0.876528601243684 @ 0:11:29.912107
Epoch  5058: reducing learning rate of group 0 to 1.2500e-04.
Epoch  6713: reducing learning rate of group 0 to 6.2500e-05.
Iteration = 1000
	batch loss = 0.5055999957091574 (e-3)
	rho = 0.9785299816504606 
	tau = 0.8852451569055172 @ 0:11:25.219216
Epoch  7514: reducing learning rate of group 0 to 3.1250e-05.
Epoch  8315: reducing learning rate of group 0 to 1.5625e-05.
Epoch  9116: reducing learning rate of group 0 to 7.8125e-06.
Epoch 10145: reducing learning rate of group 0 to 3.9063e-06.
Iteration = 1500
	batch loss = 0.5709970594450299 (e-3)
	rho = 0.981213658217751 
	tau = 0.8847923245164955 @ 0:11:27.442456
Epoch 10946: reducing learning rate of group 0 to 1.9531e-06.
Epoch 11747: reducing learning rate of group 0 to 1.0000e-06.
Iteration = 2000
	batch loss = 0.5362280228707407 (e-3)
	rho = 0.9756616346188166 
	tau = 0.879706532266437 @ 0:11:19.551238
Iteration = 2500
	batch loss = 0.41351814538107384 (e-3)
	rho = 0.9763138577788589 
	tau = 0.8750847314308933 @ 0:11:29.918981
Iteration = 3000
	batch loss = 0.6748266667792839 (e-3)
	rho = 0.9692056288504727 
	tau = 0.8805508621856721 @ 0:11:22.252788
Iteration = 3500
	batch loss = 0.4907090873790107 (e-3)
	rho = 0.9626368422533261 
	tau = 0.8666452625404429 @ 0:11:28.149281
Iteration = 4000
	batch loss = 0.46938167568961425 (e-3)
	rho = 0.981611556929251 
	tau = 0.891652404237952 @ 0:11:29.037230
Iteration = 4500
	batch loss = 0.49592206778470427 (e-3)
	rho = 0.9833170813601546 
	tau = 0.8932143437762438 @ 0:11:18.166690
Iteration = 5000
	batch loss = 0.3782101266551763 (e-3)
	rho = 0.9677477571806755 
	tau = 0.85531309528284 @ 0:10:16.571142
Iteration = 5500
	batch loss = 0.44676492689177394 (e-3)
	rho = 0.975532442912113 
	tau = 0.8761134679071089 @ 0:09:42.806596
Iteration = 6000
	batch loss = 0.5804339515244854 (e-3)
	rho = 0.9833816046766882 
	tau = 0.898863625210472 @ 0:08:14.628437
Iteration = 6500
	batch loss = 0.6106057636705893 (e-3)
	rho = 0.985954753685723 
	tau = 0.9062026121686692 @ 0:08:19.811229
Iteration = 7000
	batch loss = 1.6161517955229752 (e-3)
	rho = 0.9812261131204713 
	tau = 0.8927679458442168 @ 0:08:15.674772
Iteration = 7500
	batch loss = 0.5437634037142354 (e-3)
	rho = 0.9757596006096138 
	tau = 0.8690589670480721 @ 0:08:17.287072
Iteration = 8000
	batch loss = 0.5998974832307015 (e-3)
	rho = 0.9741041502969342 
	tau = 0.87313881789118 @ 0:08:23.654303
Iteration = 8500
	batch loss = 0.6371507437766663 (e-3)
	rho = 0.9752406652475051 
	tau = 0.8740448106942106 @ 0:08:19.359871
	validation mse decreased ( 10000000000000.0 ---> 0.3018907674898704 (e-3) ), and save the model ... 
Iteration = 9000
	batch loss = 0.4661364863360567 (e-3)
	rho = 0.9781007571205446 
	tau = 0.8846684601277994 @ 0:08:21.700820
	validation mse decreased ( 0.3018907674898704 ---> 0.21355484301845232 (e-3) ), and save the model ... 
	validation mse: 0.2906990858415763
	validation mse: 0.28382737810413045
	validation mse: 0.6643391245355209
	validation mse: 0.5076842661947012
	validation mse: 0.37406777652601403
	validation mse: 0.5433073360472918
	validation mse: 0.3704901412129402
	validation mse: 0.535608259961009
	validation mse: 0.5171476242442926
	validation mse: 0.9722748771309853
	validation mse: 0.40077806760867435
	validation mse: 0.45529051839063567
	validation mse: 0.6907938017199436
	validation mse: 1.0188357594112556
	validation mse: 0.30545885985096294
	validation mse: 0.554055068641901
	validation mse: 0.6015517810980479
	validation mse: 0.5111012747511268
	validation mse: 0.4884640841434399
	validation mse: 0.3666478643814723
	validation mse: 0.49700954308112466
	validation mse: 0.5159277562052011
	validation mse: 0.3751222152883808
	validation mse: 0.2767956132690112
	validation mse: 0.33725573991735774
	validation mse: 0.6787647648404043
	validation mse: 0.7374274854858716
	validation mse: 0.4458658521374067
	validation mse: 0.6284053530544043
	validation mse: 0.4215250024572015
	validation mse: 0.26757638591031235
	validation mse: 0.4489629777769248
	validation mse: 0.8804682766397793
	validation mse: 0.3645476885139942
	validation mse: 0.2686428495993217
	validation mse: 0.24272625024120012
	validation mse: 0.6574499420821667
	validation mse: 0.3503383385638396
	validation mse: 0.35119759384542704
	validation mse: 0.4477887973189354
	validation mse: 0.3729750122874975
	validation mse: 0.5839171136418978
	validation mse: 0.3851749561727047
	validation mse: 3.797804433852434
	validation mse: 0.6404825455198685
	validation mse: 0.2708291510740916
	validation mse: 0.4825027318050464
	validation mse: 0.44726261869072914
	validation mse: 1.01312139381965
	validation mse: 0.2990366891026497
	validation mse: 0.7456944199899832
	validation mse: 0.5672906339168549
	validation mse: 0.43824106454849243
	validation mse: 0.33671408891677856
	validation mse: 0.48042433336377144
	validation mse: 3.1100217128793397
	validation mse: 0.3260568995028734
	validation mse: 0.41578929250439006
	validation mse: 0.46974118798971176
	validation mse: 0.26991963386535645
	validation mse: 0.3464905979732672
	validation mse decreased ( 0.21355484301845232 ---> 0.18510647738973302 (e-3) ), and save the model ... 
	validation mse: 0.5760740271459023
	validation mse: 0.5408539995551109
	validation mse: 0.32072052359580994
	validation mse: 0.6140459080537161
	validation mse: 0.5058793102701505
	validation mse: 0.7133830338716507
	validation mse: 1.4654487371444702
	validation mse: 0.36632511609544355
	validation mse: 0.27897610018650687
	validation mse: 0.9727007274826368
	validation mse: 0.31471650426586467
	validation mse: 0.5207597153882186
	validation mse: 0.7734339823946357
	validation mse: 0.5116672193010647
	validation mse: 0.8106025122106075
	validation mse: 0.2880355156958103
	validation mse: 0.2611082194683453
	validation mse: 0.37207499456902343
	validation mse: 0.3440419708689054
	validation mse: 0.22704504430294037
	validation mse: 0.7878703949972987
	validation mse: 0.3185134194791317
	validation mse: 0.5968168626228968
	validation mse: 0.47732825080553687
	validation mse: 0.1971891149878502
	validation mse decreased ( 0.18510647738973302 ---> 0.14594433208306629 (e-3) ), and save the model ... 
	validation mse: 0.28278661270936334
	validation mse: 0.35622660381098586
	validation mse: 0.5770366018017133
	validation mse: 0.34321018805106485
	validation mse: 0.3641292452812195
	validation mse: 0.3337108654280504
	validation mse: 0.31685755277673405
	validation mse: 0.4025365660587947
	validation mse: 0.23252507982154685
	validation mse: 0.4385262231032053
	validation mse: 0.45838281512260437
	validation mse: 2.3505549443264804
	validation mse: 0.4995659117897352
	validation mse: 0.4136410790185134
	validation mse: 0.428380494316419
	validation mse: 0.37049423282345134
	validation mse: 0.430807638913393
	validation mse: 0.31927073063949746
	validation mse: 0.8354076836258173
	validation mse: 0.3810819362600644
	validation mse: 0.6485820934176445
	validation mse: 0.7008682005107403
	validation mse: 0.3419773497929176
	validation mse: 0.47793534584343433
	validation mse: 0.2976481864849726
	validation mse: 0.3917451637486617
	validation mse: 0.5885413909951847
	validation mse: 0.3368538183470567
	validation mse: 0.16611819000293812
	validation mse: 0.4664290975779295
	validation mse: 0.2428171845773856
	validation mse: 0.5538681956628958
	validation mse: 0.615561647961537
	validation mse: 3.872480181356271
	validation mse: 0.417531905695796
	validation mse: 0.8160595161219437
	validation mse: 0.6336744874715805
	validation mse: 0.7157914030055205
	validation mse: 0.48253837041556835
	validation mse: 0.39006800546000403
	validation mse: 0.38886267070968944
	validation mse: 0.594553876047333
	validation mse: 0.45260570632914704
	validation mse: 0.31924537383019924
	validation mse: 0.4147207736968994
	validation mse: 0.4331097472459078
	validation mse: 0.31995538001259166
	validation mse: 0.7918612534801165
	validation mse: 0.38670208926002186
	validation mse: 0.45568834990262985
	validation mse: 0.43546570775409543
	validation mse: 0.25845456402748823
	validation mse: 0.7000656301776569
	validation mse: 0.15572088692958158
	validation mse: 0.2312404786547025
	validation mse: 0.5966243613511324
	validation mse: 0.8156034474571546
	validation mse: 0.34248563771446544
	validation mse: 1.1485953629016876
	validation mse: 0.3998520225286484
	validation mse: 0.4903413696835438
	validation mse: 3.1972784471387667
	validation mse: 0.5288375696788232
	validation mse: 0.4846008277187745
	validation mse: 0.6657623437543709
	validation mse: 0.5800348287448287
	validation mse: 0.28144914424046874
	validation mse: 0.5090347801645597
	validation mse: 0.2814721254010995
	validation mse: 0.852046956618627
	validation mse: 0.31789157073944807
	validation mse: 0.3547766199335456
	validation mse: 0.2935510159780582
	validation mse: 0.2140204949925343
	validation mse: 2.094100539882978
	validation mse: 0.6364643558238944
	validation mse: 0.4134853556752205
	validation mse: 0.29261794251700246
	validation mse: 0.40340134873986244
	validation mse: 0.7682955513397852
	validation mse: 0.476524056866765
	validation mse: 0.6945271790027618
	validation mse: 0.4271002362171809
	validation mse: 0.2680920995771885
	validation mse: 0.28173989926775295
	validation mse: 0.4304490921398004
	validation mse: 0.5267717440923055
	validation mse: 0.7750623673200607
	validation mse: 3.747934183726708
	validation mse: 0.535258154074351
	validation mse: 0.5573776861031849
	validation mse: 0.32432344121237594
	validation mse: 0.6124916176001232
	validation mse: 0.42148978138963383
	validation mse: 0.6291088461875916
	validation mse: 0.471761083851258
	validation mse: 0.31494246795773506
	validation mse: 0.696244922777017
	validation mse: 0.4063711812098821
	validation mse: 1.4051381250222523

Model evaluation.
Test results:
	 test_mse = 0.6309220270031314
	 test_rho = 0.9106872240244726
	 test_tau = 0.8306140461634701
	 test_p10 = 0.8330000000000001
	 test_p20 = 0.8506666666666667
Model params:5434082
+-----------------------------+------------------------------------------------+
|          Parameter          |                     Value                      |
+=============================+================================================+
| Gt res                      | True                                           |
+-----------------------------+------------------------------------------------+
| Batch size                  | 128                                            |
+-----------------------------+------------------------------------------------+
| Channel align               | True                                           |
+-----------------------------+------------------------------------------------+
| Channel ffn size            | 128                                            |
+-----------------------------+------------------------------------------------+
| Conv channels 0             | 32                                             |
+-----------------------------+------------------------------------------------+
| Conv channels 1             | 64                                             |
+-----------------------------+------------------------------------------------+
| Conv channels 2             | 1                                              |
+-----------------------------+------------------------------------------------+
| Conv channels 3             | 256                                            |
+-----------------------------+------------------------------------------------+
| Conv dropout                | 0.1                                            |
+-----------------------------+------------------------------------------------+
| Conv l relu slope           | 0.33                                           |
+-----------------------------+------------------------------------------------+
| Data dir                    | ../datasets/                                   |
+-----------------------------+------------------------------------------------+
| Dataset                     | LINUX                                          |
+-----------------------------+------------------------------------------------+
| Device                      | cuda:3                                         |
+-----------------------------+------------------------------------------------+
| Dist mat path               | ../datasets/LINUX/LINUX_distance.npy           |
+-----------------------------+------------------------------------------------+
| Dist start decay            | 0.5                                            |
+-----------------------------+------------------------------------------------+
| Dropout                     | 0.1                                            |
+-----------------------------+------------------------------------------------+
| Embedding size              | 32                                             |
+-----------------------------+------------------------------------------------+
| Encoder ffn size            | 128                                            |
+-----------------------------+------------------------------------------------+
| Explain study               | False                                          |
+-----------------------------+------------------------------------------------+
| Gpu index                   | 3                                              |
+-----------------------------+------------------------------------------------+
| Graph transformer active    | True                                           |
+-----------------------------+------------------------------------------------+
| Iter val every              | 1                                              |
+-----------------------------+------------------------------------------------+
| Iter val start              | 9000                                           |
+-----------------------------+------------------------------------------------+
| Iterations                  | 10000                                          |
+-----------------------------+------------------------------------------------+
| Load model                  | False                                          |
+-----------------------------+------------------------------------------------+
| Loaded model signature      | IMDBMulti_2022-05-28_03-04-30-634619           |
+-----------------------------+------------------------------------------------+
| Log file path               | ../GSTLogs/LINUX_2022-06-08_14-35-02-432980/lo |
|                             | g.txt                                          |
+-----------------------------+------------------------------------------------+
| Log path                    | ../GSTLogs                                     |
+-----------------------------+------------------------------------------------+
| Lr                          | 0.0005                                         |
+-----------------------------+------------------------------------------------+
| Lr reduce factor            | 0.5                                            |
+-----------------------------+------------------------------------------------+
| Lr schedule patience        | 800                                            |
+-----------------------------+------------------------------------------------+
| Min lr                      | 1e-06                                          |
+-----------------------------+------------------------------------------------+
| Model save path             | ../GSTLogs/LINUX_2022-06-08_14-35-02-432980/be |
|                             | st_model.pt                                    |
+-----------------------------+------------------------------------------------+
| Msa bias                    | True                                           |
+-----------------------------+------------------------------------------------+
| N channel transformer heads | 4                                              |
+-----------------------------+------------------------------------------------+
| N heads                     | 8                                              |
+-----------------------------+------------------------------------------------+
| Patience                    | 100                                            |
+-----------------------------+------------------------------------------------+
| Pooling res                 | 20                                             |
+-----------------------------+------------------------------------------------+
| Repeat run                  | 0                                              |
+-----------------------------+------------------------------------------------+
| Seed                        | 2022                                           |
+-----------------------------+------------------------------------------------+
| Share qk                    | True                                           |
+-----------------------------+------------------------------------------------+
| Sim mat learning ablation   | False                                          |
+-----------------------------+------------------------------------------------+
| Temp                        | {'cur_iter': 0}                                |
+-----------------------------+------------------------------------------------+
| Use dist                    | True                                           |
+-----------------------------+------------------------------------------------+
| Wandb activate              | False                                          |
+-----------------------------+------------------------------------------------+
| Weight decay                | 0                                              |
+-----------------------------+------------------------------------------------+

Preparing dataset.

model params:330090
